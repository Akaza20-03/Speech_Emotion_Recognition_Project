# Speech_Emotion_Recognition_Project

Communication through voice is one of the main components of affective computing in Computing in humancomputer interaction. In this type of interaction, properly comprehending the meanings of the words or the linguistic category and recognizing the emotion included in the speech is essential for enhancing the performance. In order to model the emotional state, the speech waves are utilized, which bear signals standing for emotion such as happy, calm, fear, disgust. This project aims to design and develop speech-based emotion reaction prediction system, where different emotions are recognized by means of multi-layer perception (MLP) classifier. Spectral features extracted is Mel, Chroma and MFCC. Librosa package in python language is used to develop proposed algorithm and its performance is tested on taking Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) samples to differentiate emotions such as happiness, surprise, anger, neutral state, sadness, fear etc. We human is well trained thought your experience reading recognition of various emotions which make us more sensible and understandable. But in case of machine, however, it can easily understand content-based information such as information in text, audio or video but still far behind to access the depth behind the content. It is the need of the era that machine should also be trained to understand emotions correctly for better understanding and to avoid any miscommunication.
